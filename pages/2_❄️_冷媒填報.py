import streamlit as st
import pandas as pd
from datetime import datetime, date, timedelta
import gspread
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload
import unicodedata
import re

# ==========================================
# 0. ç³»çµ±è¨­å®š
# ==========================================
st.set_page_config(page_title="å†·åª’å¡«å ± - å˜‰ç¾©å¤§å­¸", page_icon="â„ï¸", layout="wide")

def get_taiwan_time():
    return datetime.utcnow() + timedelta(hours=8)

# ==========================================
# 1. CSS æ¨£å¼
# ==========================================
st.markdown("""
<style>
    [data-testid="stFileUploaderDropzone"] {
        background-color: #D6EAF8; border: 2px dashed #2E86C1; padding: 20px;
    }
    .note-text {color: #566573; font-weight: bold; font-size: 0.9rem;}
    .section-header {
        font-size: 1.15rem; font-weight: 800; color: #2C3E50; 
        border-left: 5px solid #E67E22; padding-left: 10px; margin-top: 20px; margin-bottom: 10px;
    }
</style>
""", unsafe_allow_html=True)

# 2. èº«ä»½é©—è­‰
if st.session_state.get("authentication_status") is not True:
    st.warning("ğŸ”’ è«‹å…ˆè‡³é¦–é  (Hello) ç™»å…¥ç³»çµ±")
    st.stop()

# 3. è³‡æ–™åº«é€£ç·š
REF_SHEET_ID = "1p7GsW-nrjerXhnn3pNgZzu_CdIh1Yxsm-fLJDqQ6MqA"
REF_FOLDER_ID = "1o0S56OyStDjvC5tgBWiUNqNjrpXuCQMI"

@st.cache_resource
def init_google_ref():
    oauth = st.secrets["gcp_oauth"]
    creds = Credentials(token=None, refresh_token=oauth["refresh_token"], token_uri="https://oauth2.googleapis.com/token", client_id=oauth["client_id"], client_secret=oauth["client_secret"], scopes=["https://www.googleapis.com/auth/drive", "https://www.googleapis.com/auth/spreadsheets"])
    gc = gspread.authorize(creds); drive = build('drive', 'v3', credentials=creds)
    return gc, drive

try:
    gc, drive_service = init_google_ref()
    sh_ref = gc.open_by_key(REF_SHEET_ID)
    
    # è®€å–å¿…è¦åˆ†é 
    ws_units = sh_ref.worksheet("å–®ä½è³‡è¨Š")
    ws_buildings = sh_ref.worksheet("å»ºç¯‰ç‰©æ¸…å–®")
    ws_types = sh_ref.worksheet("è¨­å‚™é¡å‹")
    ws_coef = sh_ref.worksheet("å†·åª’ä¿‚æ•¸è¡¨")
    
    try: ws_records = sh_ref.worksheet("å†·åª’å¡«å ±ç´€éŒ„")
    except: 
        ws_records = sh_ref.add_worksheet(title="å†·åª’å¡«å ±ç´€éŒ„", rows="1000", cols="15")
        ws_records.append_row(["å¡«å ±æ™‚é–“","å¡«å ±äºº","å¡«å ±äººåˆ†æ©Ÿ","æ ¡å€","æ‰€å±¬å–®ä½","å¡«å ±å–®ä½åç¨±","å»ºç¯‰ç‰©åç¨±","è¾¦å…¬å®¤ç·¨è™Ÿ","ç¶­ä¿®æ—¥æœŸ","è¨­å‚™é¡å‹","è¨­å‚™å“ç‰Œå‹è™Ÿ","å†·åª’ç¨®é¡","å†·åª’å¡«å……é‡","å‚™è¨»","ä½è­‰è³‡æ–™"])

except Exception as e:
    st.error(f"âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
    st.stop()

# 4. è³‡æ–™è®€å– (V223: å¼·åŠ›æ¯”å°æ¸…æ´—)
@st.cache_data(ttl=60)
def load_ref_data_v223():
    def clean_text(text):
        if pd.isna(text): return ""
        text = str(text)
        # æ­£è¦åŒ– Unicode
        text = unicodedata.normalize('NFKC', text)
        return text.strip()

    # çœŸç©ºæ¸…æ´—ï¼šç§»é™¤æ‰€æœ‰ç©ºç™½èˆ‡ç‰¹æ®Šç¬¦è™Ÿ (ç”¨æ–¼æ¯”å°éµå€¼)
    def vacuum_clean(text):
        if pd.isna(text): return ""
        text = str(text)
        text = unicodedata.normalize('NFKC', text)
        # ç§»é™¤æ‰€æœ‰ç©ºç™½ (åŒ…å« \t, \n, \r, \f, \v)
        return re.sub(r'\s+', '', text)

    def get_df_robust(ws):
        data = ws.get_all_values()
        if len(data) > 1:
            # ä½¿ç”¨ç¬¬ä¸€åˆ—ç•¶æ¨™é¡Œ
            headers = [clean_text(h) for h in data[0]]
            df = pd.DataFrame(data[1:], columns=headers)
            
            # å°æ‰€æœ‰æ¬„ä½é€²è¡ŒåŸºæœ¬æ¸…æ´— (é¡¯ç¤ºç”¨)
            for col in df.columns:
                df[col] = df[col].apply(clean_text)
            
            # å»ºç«‹ã€ŒçœŸç©ºå°ç…§æ¬„ã€ (æ¯”å°ç”¨ - éš±è—)
            # å°‡æ¯ä¸€æ¬„çš„å…§å®¹ç”¢ç”Ÿä¸€å€‹å°æ‡‰çš„ Clean Key
            for col in df.columns:
                df[f"_clean_{col}"] = df[col].apply(vacuum_clean)
                
            return df
        return pd.DataFrame()
    
    return get_df_robust(ws_units), get_df_robust(ws_buildings), get_df_robust(ws_types), get_df_robust(ws_coef)

df_units, df_buildings, df_types, df_coef = load_ref_data_v223()

# 5. é é¢å…§å®¹
st.title("â„ï¸ å†·åª’å¡«å ±å°ˆå€")

if st.button("ğŸ”„ åˆ·æ–°è³‡æ–™åº«", type="secondary"):
    st.cache_data.clear()
    st.rerun()

tabs = st.tabs(["ğŸ“ æ–°å¢å¡«å ±", "ğŸ“Š å‹•æ…‹æŸ¥è©¢çœ‹æ¿"])

# è¼”åŠ©å‡½å¼ï¼šçœŸç©ºæ¸…æ´—å–®ä¸€å­—ä¸²
def vacuum_str(val):
    if val is None: return ""
    return re.sub(r'\s+', '', unicodedata.normalize('NFKC', str(val)))

with tabs[0]:
    with st.form("ref_form", clear_on_submit=True):
        
        # === å€å¡Š 1: å¡«å ±äººåŸºæœ¬è³‡è¨Šå€ (2å±¤é€£å‹•) ===
        st.markdown('<div class="section-header">1. å¡«å ±äººåŸºæœ¬è³‡è¨Šå€</div>', unsafe_allow_html=True)
        
        c1, c2 = st.columns(2)
        
        # æº–å‚™è³‡æ–™æ¬„ä½åç¨± (Aæ¬„=æ‰€å±¬å–®ä½, Bæ¬„=å¡«å ±å–®ä½åç¨±)
        # ç‚ºäº†ä¿éšªï¼Œæˆ‘å€‘ä½¿ç”¨ iloc æŠ“å–åŸå§‹æ¬„ä½åç¨±ï¼Œä¸ç®¡å®ƒå«ä»€éº¼
        col_name_A = df_units.columns[0] if not df_units.empty else "æ‰€å±¬å–®ä½"
        col_name_B = df_units.columns[1] if not df_units.empty and len(df_units.columns) > 1 else "å¡«å ±å–®ä½åç¨±"
        
        # 1-1. æ‰€å±¬å–®ä½
        unit_depts = []
        if not df_units.empty:
            unit_depts = sorted([x for x in df_units[col_name_A].unique() if x])
        sel_dept = c1.selectbox("æ‰€å±¬å–®ä½", unit_depts, index=None, placeholder="è«‹é¸æ“‡å–®ä½...")
        
        # 1-2. å¡«å ±å–®ä½åç¨± (ä½¿ç”¨å¼·åŠ›æ¯”å°)
        unit_names = []
        if sel_dept and not df_units.empty:
            # æ¯”å°é‚è¼¯ï¼šæ¯”å°ã€ŒçœŸç©ºç‰ˆã€çš„è³‡æ–™
            # å°‡ä½¿ç”¨è€…é¸çš„å…§å®¹ã€ŒçœŸç©ºåŒ–ã€
            clean_sel = vacuum_str(sel_dept)
            # åœ¨è³‡æ–™åº«æ‰¾ã€ŒçœŸç©ºç‰ˆ A æ¬„ã€ç­‰æ–¼ clean_sel çš„è³‡æ–™
            clean_col_A = f"_clean_{col_name_A}" # é€™æ˜¯æˆ‘å€‘å‰›å‰›å·å»ºçš„æ¬„ä½
            
            mask = df_units[clean_col_A] == clean_sel
            
            # å–å‡ºå°æ‡‰çš„ B æ¬„
            if mask.any():
                unit_names = sorted([x for x in df_units[mask][col_name_B].unique() if x])
            else:
                # è¬ä¸€çœŸçš„æ²’å°åˆ°ï¼Œé¡¯ç¤ºé™¤éŒ¯ (æ­£å¸¸æƒ…æ³ä¸æœƒç™¼ç”Ÿ)
                st.warning(f"ç¯©é¸ç•°å¸¸ï¼šæ‰¾ä¸åˆ° '{sel_dept}' çš„ä¸‹å±¤å–®ä½ã€‚")
                
        sel_unit_name = c2.selectbox("å¡«å ±å–®ä½åç¨±", unit_names, index=None, placeholder="è«‹å…ˆé¸æ“‡æ‰€å±¬å–®ä½...")
        
        # 1-3. é–‹æ”¾æ¬„ä½
        c3, c4 = st.columns(2)
        name = c3.text_input("å¡«å ±äºº")
        ext = c4.text_input("å¡«å ±äººåˆ†æ©Ÿ")
        
        st.markdown("---")
        
        # === å€å¡Š 2: è©³ç´°ä½ç½®è³‡è¨Šå€ (2å±¤é€£å‹•) ===
        st.markdown('<div class="section-header">2. è©³ç´°ä½ç½®è³‡è¨Šå€</div>', unsafe_allow_html=True)
        
        c6, c7 = st.columns(2)
        
        # æº–å‚™è³‡æ–™æ¬„ä½ (A=æ ¡å€, B=å»ºç¯‰ç‰©)
        b_col_A = df_buildings.columns[0] if not df_buildings.empty else "æ ¡å€"
        b_col_B = df_buildings.columns[1] if not df_buildings.empty and len(df_buildings.columns) > 1 else "å»ºç¯‰ç‰©åç¨±"
        
        # 2-1. å¡«å ±å–®ä½æ‰€åœ¨æ ¡å€
        loc_campuses = []
        if not df_buildings.empty:
            loc_campuses = sorted([x for x in df_buildings[b_col_A].unique() if x])
        sel_loc_campus = c6.selectbox("å¡«å ±å–®ä½æ‰€åœ¨æ ¡å€", loc_campuses, index=None, placeholder="è«‹é¸æ“‡æ ¡å€...")
        
        # 2-2. å»ºç¯‰ç‰©åç¨± (ä½¿ç”¨å¼·åŠ›æ¯”å°)
        buildings = []
        if sel_loc_campus and not df_buildings.empty:
            clean_sel_campus = vacuum_str(sel_loc_campus)
            clean_b_col_A = f"_clean_{b_col_A}"
            
            mask_b = df_buildings[clean_b_col_A] == clean_sel_campus
            
            if mask_b.any():
                buildings = sorted([x for x in df_buildings[mask_b][b_col_B].unique() if x])
                
        sel_build = c6.selectbox("å»ºç¯‰ç‰©åç¨±", buildings, index=None, placeholder="è«‹å…ˆé¸æ“‡æ ¡å€...")
        
        # 2-3. è¾¦å…¬å®¤
        office = c7.text_input("è¾¦å…¬å®¤ç·¨è™Ÿ", placeholder="ä¾‹å¦‚ï¼š202è¾¦å…¬å®¤ã€306ç ”ç©¶å®¤")
        
        st.markdown("---")
        
        # === å€å¡Š 3: è¨­å‚™ä¿®ç¹•è³‡è¨Š ===
        st.markdown('<div class="section-header">3. è¨­å‚™ä¿®ç¹•å†·åª’å¡«å……è³‡è¨Šå€</div>', unsafe_allow_html=True)
        c8, c9 = st.columns(2)
        r_date = c8.date_input("ç¶­ä¿®æ—¥æœŸ (çµ±ä¸€å¡«å¯«ç™¼ç¥¨æ—¥æœŸ)", datetime.today())
        
        # è¨­å‚™é¡å‹ (Aæ¬„)
        e_types = []
        if not df_types.empty:
            e_types = sorted([x for x in df_types.iloc[:, 0].unique() if x])
        sel_etype = c9.selectbox("è¨­å‚™é¡å‹", e_types, index=None, placeholder="è«‹é¸æ“‡...")
        
        c10, c11 = st.columns(2)
        e_model = c10.text_input("è¨­å‚™å“ç‰Œå‹è™Ÿ", placeholder="ä¾‹å¦‚ï¼šåœ‹éš› CS-100FL+CU-100FLC")
        
        # å†·åª’ç¨®é¡ (Bæ¬„, ç¬¬äºŒæ¬„)
        r_types = []
        if not df_coef.empty and len(df_coef.columns) > 1:
            r_types = sorted([x for x in df_coef.iloc[:, 1].unique() if x])
        sel_rtype = c11.selectbox("å†·åª’ç¨®é¡", r_types, index=None, placeholder="è«‹é¸æ“‡...")
        
        amount = st.number_input("å†·åª’å¡«å……é‡ (å…¬æ–¤)", min_value=0.0, step=0.1, format="%.2f")
        
        st.markdown("è«‹ä¸Šå‚³å†·åª’å¡«å……å–®æ“šä½è­‰è³‡æ–™")
        f_file = st.file_uploader("ä¸Šå‚³ä½è­‰ (å¿…å¡«)", type=['pdf', 'jpg', 'png'], label_visibility="collapsed")
        
        st.markdown("---")
        note = st.text_input("å‚™è¨»å…§å®¹", placeholder="å‚™è¨» (é¸å¡«)")
        
        st.markdown('<div style="background-color:#F8F9F9; padding:10px; font-size:0.9rem;"><strong>ğŸ“œ å€‹è³‡è²æ˜</strong>ï¼šè’é›†ç›®çš„ç‚ºè¨­å‚™ç®¡ç†èˆ‡ç¢³ç›¤æŸ¥ï¼Œä¿å­˜è‡³ç”³å ±å¾Œç¬¬äºŒå¹´ã€‚</div>', unsafe_allow_html=True)
        agree = st.checkbox("æˆ‘å·²é–±è®€ä¸¦åŒæ„å€‹è³‡è²æ˜")
        
        submitted = st.form_submit_button("ğŸš€ ç¢ºèªé€å‡º", use_container_width=True)
        
        if submitted:
            if not agree: st.error("âŒ è«‹å‹¾é¸åŒæ„è²æ˜")
            elif not sel_dept or not sel_unit_name: st.warning("âš ï¸ è«‹å®Œæ•´é¸æ“‡ã€åŸºæœ¬è³‡è¨Šã€‘ä¸­çš„å–®ä½è³‡è¨Š")
            elif not name or not ext: st.warning("âš ï¸ è«‹å¡«å¯«å¡«å ±äººèˆ‡åˆ†æ©Ÿ")
            elif not sel_loc_campus or not sel_build: st.warning("âš ï¸ è«‹å®Œæ•´é¸æ“‡ã€ä½ç½®è³‡è¨Šã€‘ä¸­çš„æ ¡å€èˆ‡å»ºç¯‰ç‰©")
            elif not sel_etype or not sel_rtype: st.warning("âš ï¸ è«‹é¸æ“‡è¨­å‚™é¡å‹èˆ‡å†·åª’ç¨®é¡")
            elif not f_file: st.error("âš ï¸ è«‹ä¸Šå‚³ä½è­‰è³‡æ–™")
            else:
                try:
                    f_file.seek(0); f_ext = f_file.name.split('.')[-1]
                    # æª”åé‚è¼¯
                    clean_name = f"{sel_loc_campus}_{sel_dept}_{sel_unit_name}_{r_date}_{sel_etype}_{sel_rtype}.{f_ext}"
                    
                    meta = {'name': clean_name, 'parents': [REF_FOLDER_ID]}
                    media = MediaIoBaseUpload(f_file, mimetype=f_file.type, resumable=True)
                    file = drive_service.files().create(body=meta, media_body=media, fields='webViewLink').execute()
                    link = file.get('webViewLink')
                    
                    current_time = get_taiwan_time().strftime("%Y-%m-%d %H:%M:%S")
                    
                    # å¯«å…¥è³‡æ–™
                    row_data = [
                        current_time, name, ext, sel_loc_campus, sel_dept, sel_unit_name, 
                        sel_build, office, str(r_date), sel_etype, e_model, 
                        sel_rtype, amount, note, link
                    ]
                    ws_records.append_row(row_data)
                    st.success("âœ… å†·åª’å¡«å ±æˆåŠŸï¼")
                    st.balloons()
                except Exception as e:
                    st.error(f"ä¸Šå‚³æˆ–å¯«å…¥å¤±æ•—: {e}")

with tabs[1]:
    st.info("ğŸš§ å‹•æ…‹æŸ¥è©¢çœ‹æ¿é–‹ç™¼ä¸­...")